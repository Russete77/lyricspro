# üöÄ Guia de Deploy - TranscritorAI Pro

## üìã Pr√©-requisitos

- [ ] Conta no GitHub (gr√°tis)
- [ ] Conta no Render.com (gr√°tis - sem cart√£o necess√°rio)
- [ ] Conta no Vercel (gr√°tis - sem cart√£o necess√°rio)
- [ ] OpenAI API Key (opcional - para p√≥s-processamento com GPT-4o)

---

## üîß PARTE 1: Preparar Reposit√≥rio GitHub

### 1. Inicializar Git (se ainda n√£o fez)

```bash
cd C:\Users\erick\transcriptioon-pro
git init
git add .
git commit -m "Initial commit - TranscritorAI Pro"
```

### 2. Criar reposit√≥rio no GitHub

1. Acesse: https://github.com/new
2. Nome: `transcriptor-ai-pro`
3. Visibilidade: `Private` (ou Public se quiser)
4. **N√ÉO** inicialize com README
5. Clique em `Create repository`

### 3. Push para GitHub

```bash
git remote add origin https://github.com/SEU-USUARIO/transcriptor-ai-pro.git
git branch -M main
git push -u origin main
```

---

## üé® PARTE 2: Deploy do Frontend (Vercel)

### Op√ß√£o A: Via Dashboard (Mais F√°cil)

1. Acesse: https://vercel.com/new
2. Conecte sua conta do GitHub
3. Selecione o reposit√≥rio `transcriptor-ai-pro`
4. Configure:
   - **Framework Preset:** Next.js
   - **Root Directory:** `frontend`
   - **Build Command:** `npm run build`
   - **Output Directory:** `.next`
   - **Install Command:** `npm install`

5. **Environment Variables:**
   ```
   NEXT_PUBLIC_API_URL=https://transcriptor-api.onrender.com
   ```
   ‚ö†Ô∏è **IMPORTANTE:** Voc√™ vai pegar esta URL depois do deploy do backend!

6. Clique em `Deploy`

### Op√ß√£o B: Via CLI

```bash
cd frontend
npm i -g vercel
vercel login
vercel

# Quando perguntar:
# Set up and deploy? Y
# Which scope? [seu usuario]
# Link to existing project? N
# What's your project's name? transcriptor-pro
# In which directory is your code located? ./
# Want to override the settings? N

# Deploy para produ√ß√£o:
vercel --prod
```

### Resultado esperado:
‚úÖ Frontend dispon√≠vel em: `https://transcriptor-pro-seu-usuario.vercel.app`

---

## üî• PARTE 3: Deploy do Backend (Render)

### Op√ß√£o A: Via Blueprint (Autom√°tico - RECOMENDADO)

1. Acesse: https://dashboard.render.com/
2. Clique em `New` ‚Üí `Blueprint`
3. Conecte sua conta do GitHub
4. Selecione o reposit√≥rio `transcriptor-ai-pro`
5. Render vai detectar o arquivo `render.yaml` automaticamente
6. **Nome do blueprint:** `transcriptor-ai-pro`
7. Clique em `Apply`

Render vai criar automaticamente:
- ‚úÖ Web Service (FastAPI API)
- ‚úÖ Worker Service (Celery)
- ‚úÖ PostgreSQL (1GB gr√°tis)
- ‚úÖ Redis (25MB gr√°tis)

### Op√ß√£o B: Manual (Passo a Passo)

#### 3.1 Criar PostgreSQL

1. Dashboard Render ‚Üí `New` ‚Üí `PostgreSQL`
2. Nome: `transcriptor-db`
3. Database: `transcriptor_ai`
4. Region: `Oregon` (free)
5. Plan: `Free`
6. Clique em `Create Database`
7. **Copie a `Internal Database URL`** (vai precisar)

#### 3.2 Criar Redis

1. Dashboard Render ‚Üí `New` ‚Üí `Redis`
2. Nome: `transcriptor-redis`
3. Region: `Oregon` (free)
4. Plan: `Free`
5. Clique em `Create Redis`
6. **Copie a `Internal Redis URL`** (vai precisar)

#### 3.3 Criar Web Service (API)

1. Dashboard Render ‚Üí `New` ‚Üí `Web Service`
2. Conecte o reposit√≥rio GitHub
3. Configure:
   - **Name:** `transcriptor-api`
   - **Region:** Oregon (free)
   - **Branch:** `main`
   - **Root Directory:** `backend`
   - **Runtime:** Python 3
   - **Build Command:** `pip install -r requirements.production.txt`
   - **Start Command:** `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
   - **Plan:** Free

4. **Environment Variables** (clique em `Advanced`):
   ```
   PYTHON_VERSION=3.11.0
   DATABASE_URL=[Cole a Internal Database URL do PostgreSQL]
   REDIS_URL=[Cole a Internal Redis URL]
   ENVIRONMENT=production
   CORS_ORIGINS=https://transcriptor-pro-seu-usuario.vercel.app
   WHISPER_MODEL_SIZE=base
   WHISPER_DEVICE=cpu
   MAX_FILE_SIZE_MB=100
   MAX_DURATION_MINUTES=30
   ```

5. **Health Check Path:** `/api/health`

6. Clique em `Create Web Service`

#### 3.4 Criar Worker Service (Celery)

1. Dashboard Render ‚Üí `New` ‚Üí `Background Worker`
2. Conecte o reposit√≥rio GitHub
3. Configure:
   - **Name:** `transcriptor-worker`
   - **Region:** Oregon (free)
   - **Branch:** `main`
   - **Root Directory:** `backend`
   - **Runtime:** Python 3
   - **Build Command:** `pip install -r requirements.production.txt`
   - **Start Command:** `celery -A app.workers.celery_app worker --loglevel=info --concurrency=1 -Q cpu-tasks --pool=solo`
   - **Plan:** Free

4. **Environment Variables** (mesmas da API):
   ```
   PYTHON_VERSION=3.11.0
   DATABASE_URL=[Cole a Internal Database URL]
   REDIS_URL=[Cole a Internal Redis URL]
   ENVIRONMENT=production
   WHISPER_MODEL_SIZE=base
   WHISPER_DEVICE=cpu
   ```

5. Clique em `Create Background Worker`

### Resultado esperado:
‚úÖ API dispon√≠vel em: `https://transcriptor-api.onrender.com`

---

## üîó PARTE 4: Conectar Frontend com Backend

### 1. Pegar URL do Backend

No dashboard do Render, clique no servi√ßo `transcriptor-api` e copie a URL:
```
https://transcriptor-api.onrender.com
```

### 2. Atualizar Frontend na Vercel

1. Vercel Dashboard ‚Üí Seu projeto ‚Üí `Settings` ‚Üí `Environment Variables`
2. Edite `NEXT_PUBLIC_API_URL`:
   ```
   NEXT_PUBLIC_API_URL=https://transcriptor-api.onrender.com
   ```
3. Clique em `Save`
4. V√° em `Deployments` ‚Üí Clique nos 3 pontinhos do √∫ltimo deploy ‚Üí `Redeploy`

### 3. Atualizar CORS no Backend

1. Render Dashboard ‚Üí `transcriptor-api` ‚Üí `Environment`
2. Edite `CORS_ORIGINS` com a URL real do Vercel:
   ```
   CORS_ORIGINS=https://transcriptor-pro-seu-usuario.vercel.app,http://localhost:3000
   ```
3. Clique em `Save Changes`
4. Render vai fazer redeploy autom√°tico

---

## ‚úÖ PARTE 5: Testar Deploy

### 1. Verificar Health Check

Abra no navegador:
```
https://transcriptor-api.onrender.com/api/health
```

Deve retornar:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "services": {
    "database": "connected",
    "redis": "connected"
  }
}
```

### 2. Verificar Frontend

Abra:
```
https://transcriptor-pro-seu-usuario.vercel.app
```

Deve carregar a landing page normalmente.

### 3. Testar Upload

1. Clique em `Come√ßar Agora`
2. Fa√ßa upload de um arquivo de √°udio pequeno
3. Aguarde processamento

‚ö†Ô∏è **IMPORTANTE:** O primeiro upload pode demorar ~2-3 minutos porque:
- Render est√° baixando os modelos do Whisper
- Servidor estava "dormindo" (spin down)

---

## üêõ Troubleshooting

### Problema: Backend n√£o responde (503 Error)

**Solu√ß√£o:** Aguarde 30-60 segundos. Render est√° "acordando" o servidor.

### Problema: CORS Error no Frontend

**Solu√ß√£o:** Verifique se o `CORS_ORIGINS` no backend tem a URL EXATA do Vercel (sem / no final).

### Problema: Database connection failed

**Solu√ß√£o:**
1. Verifique se o PostgreSQL est√° rodando no Render
2. Confirme que a `DATABASE_URL` est√° correta
3. Espere alguns minutos (database pode estar inicializando)

### Problema: Worker n√£o processa

**Solu√ß√£o:**
1. Verifique logs do worker no Render
2. Confirme que `REDIS_URL` est√° correta
3. Verifique se o worker est√° rodando (Render Dashboard)

### Problema: Whisper model download failed

**Solu√ß√£o:**
1. Primeira execu√ß√£o √© lenta (download do modelo)
2. Use `WHISPER_MODEL_SIZE=base` (mais r√°pido, 74MB)
3. Logs v√£o mostrar progresso do download

---

## üéØ Melhorias P√≥s-Deploy

### 1. Evitar Spin Down (Gr√°tis)

Use **UptimeRobot** para fazer ping a cada 14 minutos:

1. Crie conta: https://uptimerobot.com/
2. Add New Monitor
3. Monitor Type: `HTTP(s)`
4. URL: `https://transcriptor-api.onrender.com/api/health`
5. Monitoring Interval: `5 minutes`
6. Clique em `Create Monitor`

Pronto! Seu backend nunca mais vai dormir üéâ

### 2. Adicionar OpenAI (Opcional)

Se quiser p√≥s-processamento com GPT-4o:

1. Pegar API Key: https://platform.openai.com/api-keys
2. Render ‚Üí `transcriptor-api` ‚Üí Environment
3. Adicionar:
   ```
   OPENAI_API_KEY=sk-seu-key-aqui
   ```
4. Save Changes

### 3. Custom Domain (Opcional)

**Frontend (Vercel):**
1. Vercel ‚Üí Seu projeto ‚Üí `Settings` ‚Üí `Domains`
2. Add seu dom√≠nio (ex: `transcriptor.com`)
3. Configurar DNS conforme instru√ß√µes

**Backend (Render):**
1. Render ‚Üí `transcriptor-api` ‚Üí `Settings` ‚Üí `Custom Domains`
2. Add dom√≠nio (ex: `api.transcriptor.com`)
3. Configurar DNS

---

## üìä Monitoramento

### Logs

**Backend:**
```
Render Dashboard ‚Üí transcriptor-api ‚Üí Logs
```

**Worker:**
```
Render Dashboard ‚Üí transcriptor-worker ‚Üí Logs
```

**Frontend:**
```
Vercel Dashboard ‚Üí Seu projeto ‚Üí Deployments ‚Üí [clique no deploy] ‚Üí Logs
```

### M√©tricas

**Render:**
- CPU, RAM, Network no dashboard
- PostgreSQL: storage usado
- Redis: mem√≥ria usada

**Vercel:**
- Bandwidth
- Build time
- Function executions

---

## üí∞ Custos

### Free Tier (atual):
- Vercel: FREE
- Render API: FREE (750h/m√™s)
- Render Worker: FREE (750h/m√™s)
- PostgreSQL: FREE (1GB)
- Redis: FREE (25MB)
- **Total: $0/m√™s** üéâ

### Quando crescer:
- Render Starter: $7/servi√ßo = $21/m√™s
- PostgreSQL Starter: $7/m√™s
- Redis Starter: $7/m√™s
- **Total: ~$35/m√™s**

---

## üéâ Deploy Completo!

Seu app est√° rodando em produ√ß√£o! üöÄ

**URLs:**
- Frontend: `https://transcriptor-pro-seu-usuario.vercel.app`
- Backend API: `https://transcriptor-api.onrender.com`
- Docs: `https://transcriptor-api.onrender.com/docs`

**Pr√≥ximos passos:**
1. Testar com usu√°rios reais
2. Coletar feedback
3. Iterar e melhorar
4. Monetizar quando validado

Boa sorte! üí™
