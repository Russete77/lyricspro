# ğŸš€ Guia de Deploy - Transcription Pro

## Arquitetura HÃ­brida (GrÃ¡tis + GPU Local)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Backend    â”‚â”€â”€â”€â”€â”€â–¶â”‚   PostgreSQL   â”‚
â”‚  (Vercel)   â”‚      â”‚   (Render)   â”‚      â”‚   (Render)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”œâ”€â”€â”€â”€â”€â–¶ Redis (Render)
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                     â”‚             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Worker  â”‚  â”‚ Worker GPU    â”‚
              â”‚  CPU     â”‚  â”‚ (Seu PC)      â”‚
              â”‚ (Render) â”‚  â”‚  âš¡ GTX 1650  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                Backup        Performance!
```

---

## ğŸ“‹ PrÃ©-requisitos

- [ ] Conta no [Render](https://render.com) (grÃ¡tis)
- [ ] Conta no [Vercel](https://vercel.com) (grÃ¡tis)
- [ ] RepositÃ³rio no GitHub
- [ ] OpenAI API Key (para GPT-4o)

---

## ğŸ”§ Passo 1: Preparar RepositÃ³rio GitHub

### 1.1 Inicializar Git (se ainda nÃ£o foi)
```bash
cd C:\Users\erick\transcriptioon-pro
git init
git add .
git commit -m "Initial commit: Transcription Pro com GPU"
```

### 1.2 Criar repositÃ³rio no GitHub
1. Acesse: https://github.com/new
2. Nome: `transcription-pro`
3. DescriÃ§Ã£o: "AI-powered music transcription with GPU acceleration"
4. Visibilidade: Private (recomendado) ou Public
5. **NÃƒO** marque "Initialize with README"

### 1.3 Push para GitHub
```bash
git remote add origin https://github.com/SEU_USERNAME/transcription-pro.git
git branch -M main
git push -u origin main
```

---

## â˜ï¸ Passo 2: Deploy Backend no Render

### 2.1 Criar Conta e Conectar GitHub
1. Acesse: https://render.com
2. Sign up com GitHub
3. Autorize acesso ao repositÃ³rio `transcription-pro`

### 2.2 Deploy AutomÃ¡tico com render.yaml
O arquivo `render.yaml` jÃ¡ estÃ¡ configurado! O Render vai criar automaticamente:
- âœ… **Web Service** (API FastAPI)
- âœ… **Worker CPU** (Celery backup)
- âœ… **PostgreSQL** (banco de dados)
- âœ… **Redis** (fila do Celery)

**Passos:**
1. Dashboard Render â†’ "New" â†’ "Blueprint"
2. Conecte o repo `transcription-pro`
3. Branch: `main`
4. Render detecta `render.yaml` automaticamente
5. Clique "Apply"

### 2.3 Configurar VariÃ¡veis de Ambiente Adicionais
ApÃ³s criar os serviÃ§os, adicione manualmente:

**Em `transcription-pro-api` (Web Service):**
- `OPENAI_API_KEY`: sua chave da OpenAI (obrigatÃ³rio para GPT-4o)
- `CORS_ORIGINS`: `https://SEU-APP.vercel.app,http://localhost:3000`

**Em `transcription-pro-worker-cpu` (Worker):**
- `OPENAI_API_KEY`: mesma chave

### 2.4 Aguardar Deploy
- Backend API: ~5-10 minutos
- Worker CPU: ~5-10 minutos
- Databases: ~2-3 minutos

**URL da API:** `https://transcription-pro-api.onrender.com`

---

## ğŸŒ Passo 3: Deploy Frontend na Vercel

### 3.1 Criar Projeto na Vercel
1. Acesse: https://vercel.com
2. "Add New Project"
3. Import do GitHub: `transcription-pro`
4. Framework: **Next.js** (detectado automaticamente)
5. Root Directory: `frontend`

### 3.2 Configurar VariÃ¡veis de Ambiente
```env
NEXT_PUBLIC_API_URL=https://transcription-pro-api.onrender.com
NEXT_PUBLIC_APP_URL=https://SEU-APP.vercel.app
```

### 3.3 Deploy
- Clique "Deploy"
- Aguardar ~2-3 minutos

**URL do Frontend:** `https://SEU-APP.vercel.app`

### 3.4 Atualizar CORS no Backend
Volte no Render e atualize `CORS_ORIGINS` com a URL real da Vercel.

---

## ğŸ’» Passo 4: Worker GPU Local (Seu PC)

### 4.1 Criar arquivo `.env.local` no backend
```env
# Copie do .env e adicione:
REDIS_URL=redis://default:SEU_REDIS_PASSWORD@red-xxx.oregon.render.com:6379
DATABASE_URL=postgresql://user:pass@dpg-xxx.oregon.render.com/transcriptions
CELERY_BROKER_URL=redis://default:SEU_REDIS_PASSWORD@red-xxx.oregon.render.com:6379
CELERY_RESULT_BACKEND=redis://default:SEU_REDIS_PASSWORD@red-xxx.oregon.render.com:6379

# GPU Settings
ENABLE_VOCAL_SEPARATION=true
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=int8
WHISPER_MODEL_SIZE=large-v3

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o
```

**Como obter as URLs:**
1. Redis URL: Render Dashboard â†’ `transcription-redis` â†’ "Internal Redis URL"
2. Database URL: Render Dashboard â†’ `transcription-db` â†’ "Internal Database URL"

### 4.2 Rodar Worker GPU Localmente
```bash
cd C:\Users\erick\transcriptioon-pro\backend

# Ativar ambiente conda
conda activate transcription

# Rodar worker
celery -A app.workers.celery_app worker --loglevel=info --pool=solo -Q gpu-tasks,celery --hostname=gpu-worker@%h
```

### 4.3 Manter Worker Rodando (Opcional)
**Windows - Criar Batch Script:**
```batch
@echo off
cd C:\Users\erick\transcriptioon-pro\backend
call conda activate transcription
celery -A app.workers.celery_app worker --loglevel=info --pool=solo -Q gpu-tasks,celery --hostname=gpu-worker@%h
```

Salvar como `start-gpu-worker.bat` e criar atalho no "Inicializar" do Windows.

---

## âš¡ Como Funciona a SoluÃ§Ã£o HÃ­brida

### CenÃ¡rio 1: PC Ligado (GPU Worker Online)
```
Upload â†’ Render API â†’ Redis Queue
                         â†“
                    GPU Worker (Seu PC)
                    â”œâ”€ Demucs GPU (~23s)
                    â”œâ”€ Whisper GPU (rÃ¡pido)
                    â””â”€ GPT-4o (correÃ§Ã£o)
                         â†“
                    100% Perfeito! âœ…
```

### CenÃ¡rio 2: PC Desligado (GPU Worker Offline)
```
Upload â†’ Render API â†’ Redis Queue
                         â†“
                    CPU Worker (Render)
                    â”œâ”€ Sem Demucs âŒ
                    â”œâ”€ Whisper CPU (5-10min)
                    â””â”€ GPT-4o (correÃ§Ã£o)
                         â†“
                    90-95% Qualidade ğŸ¢
```

---

## ğŸ§ª Teste de Deploy

### Teste 1: Backend API
```bash
curl https://transcription-pro-api.onrender.com/health
# Esperado: {"status":"healthy"}
```

### Teste 2: Frontend
Abra no navegador: `https://SEU-APP.vercel.app`

### Teste 3: Upload e Processamento
1. Acesse o frontend
2. FaÃ§a upload de uma mÃºsica de teste
3. Aguarde processamento
4. Verifique qualidade da transcriÃ§Ã£o

---

## ğŸ“Š Monitoramento

### Render Dashboard
- **API Logs**: Ver requests e erros
- **Worker Logs**: Ver jobs processados
- **Databases**: Monitorar uso

### Celery Flower (Opcional)
Adicionar worker de monitoramento:
```bash
celery -A app.workers.celery_app flower --port=5555
```

---

## ğŸ’° Custos Estimados

### GrÃ¡tis:
- âœ… Render (Backend + Worker CPU + PostgreSQL + Redis)
- âœ… Vercel (Frontend)
- âœ… GPU Local (seu PC)

### Pago:
- ğŸ’µ OpenAI GPT-4o: ~$0.01-0.05 por mÃºsica
- ğŸ’µ Energia elÃ©trica PC: desprezÃ­vel

**Total mensal (10 mÃºsicas/dia):** ~$3-15/mÃªs apenas OpenAI

---

## ğŸ”’ SeguranÃ§a

### VariÃ¡veis Secretas
**NUNCA commit:**
- âŒ `OPENAI_API_KEY`
- âŒ `DATABASE_URL`
- âŒ `REDIS_URL`

Sempre usar variÃ¡veis de ambiente no Render/Vercel.

### CORS
SÃ³ permitir origens conhecidas:
```
https://transcription-pro.vercel.app
http://localhost:3000  (desenvolvimento)
```

---

## ğŸ› Troubleshooting

### Problema: Worker nÃ£o conecta no Redis
**SoluÃ§Ã£o:** Verificar `REDIS_URL` no `.env.local`

### Problema: "No workers available"
**SoluÃ§Ã£o:**
- Verificar se worker GPU estÃ¡ rodando
- Fallback para worker CPU do Render

### Problema: Frontend nÃ£o conecta no Backend
**SoluÃ§Ã£o:**
- Verificar `NEXT_PUBLIC_API_URL` na Vercel
- Verificar `CORS_ORIGINS` no Render

### Problema: Render suspende serviÃ§os (Free Tier)
**SoluÃ§Ã£o:**
- Free tier desliga apÃ³s 15min inatividade
- Primeiro request apÃ³s inatividade demora ~30s (cold start)
- Considerar upgrade para Starter ($7/mÃªs) se necessÃ¡rio

---

## ğŸš€ PrÃ³ximas Melhorias

Quando quiser escalar:

1. **RunPod GPU Cloud** (~$0.02/mÃºsica)
   - Disponibilidade 24/7
   - NÃ£o precisa PC ligado

2. **Render Paid Plan** ($7/mÃªs)
   - Sem sleep
   - Mais RAM

3. **Custom Domain**
   - `transcription.seudomain.com`

---

## ğŸ“ Suporte

Problemas? Verifique:
1. Logs do Render (Backend/Worker)
2. Console do navegador (Frontend)
3. Worker GPU local (se rodando)

---

**Pronto para deploy?** Siga os passos acima! ğŸ‰
